#!/usr/bin/env python3
"""
LLM åç«¯æµ‹è¯•è„šæœ¬

æµ‹è¯•é…ç½®çš„ LLM åç«¯æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv(project_root / ".env")

from ominime.llm_backend import get_llm_backend, LLMMessage


def test_backend():
    """æµ‹è¯• LLM åç«¯"""
    print("ğŸ§ª æµ‹è¯• LLM åç«¯é…ç½®")
    print("=" * 60)
    print()
    
    # æ˜¾ç¤ºé…ç½®
    backend_type = os.getenv("LLM_BACKEND", "openai")
    print(f"ğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"   LLM_BACKEND: {backend_type}")
    
    if backend_type == "openai":
        print(f"   OPENAI_MODEL: {os.getenv('OPENAI_MODEL', 'gpt-4o-mini')}")
        print(f"   OPENAI_BASE_URL: {os.getenv('OPENAI_BASE_URL', 'é»˜è®¤')}")
        api_key = os.getenv("OPENAI_API_KEY", "")
        if api_key:
            print(f"   OPENAI_API_KEY: {api_key[:10]}...{api_key[-4:]}")
        else:
            print(f"   OPENAI_API_KEY: âŒ æœªé…ç½®")
    elif backend_type == "qwen-local":
        print(f"   QWEN_MODEL: {os.getenv('QWEN_MODEL', 'Qwen/Qwen2.5-7B-Instruct')}")
    elif backend_type == "ollama":
        print(f"   OLLAMA_MODEL: {os.getenv('OLLAMA_MODEL', 'qwen2.5:7b')}")
        print(f"   OLLAMA_BASE_URL: {os.getenv('OLLAMA_BASE_URL', 'http://localhost:11434')}")
    
    print()
    print("-" * 60)
    print()
    
    # è·å–åç«¯
    print("ğŸ”Œ åˆå§‹åŒ–åç«¯...")
    try:
        backend = get_llm_backend()
        if backend is None:
            print("âŒ åç«¯åˆå§‹åŒ–å¤±è´¥")
            print()
            print("è¯·æ£€æŸ¥:")
            print("  1. .env æ–‡ä»¶æ˜¯å¦æ­£ç¡®é…ç½®")
            print("  2. å¿…è¦çš„ä¾èµ–æ˜¯å¦å·²å®‰è£…")
            print("  3. æœåŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œ (Ollama)")
            return False
        
        print(f"âœ… åç«¯åˆå§‹åŒ–æˆåŠŸ: {backend.__class__.__name__}")
        print()
    except Exception as e:
        print(f"âŒ åç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        return False
    
    # æ£€æŸ¥å¯ç”¨æ€§
    print("ğŸ” æ£€æŸ¥åç«¯å¯ç”¨æ€§...")
    try:
        if not backend.is_available():
            print("âŒ åç«¯ä¸å¯ç”¨")
            return False
        print("âœ… åç«¯å¯ç”¨")
        print()
    except Exception as e:
        print(f"âŒ æ£€æŸ¥å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•å¯¹è¯
    print("ğŸ’¬ æµ‹è¯•å¯¹è¯åŠŸèƒ½...")
    print()
    
    test_messages = [
        LLMMessage(role="system", content="ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹ã€‚"),
        LLMMessage(role="user", content="è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚")
    ]
    
    try:
        print("   å‘é€æµ‹è¯•æ¶ˆæ¯...")
        response = backend.chat(
            messages=test_messages,
            temperature=0.7,
            max_tokens=100
        )
        
        print()
        print("   ğŸ“¨ å“åº”:")
        print(f"      æ¨¡å‹: {response.model}")
        print(f"      å†…å®¹: {response.content}")
        
        if response.usage:
            print(f"      Token ä½¿ç”¨: {response.usage}")
        
        print()
        print("âœ… å¯¹è¯æµ‹è¯•æˆåŠŸï¼")
        print()
        
    except Exception as e:
        print(f"âŒ å¯¹è¯æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # æ€§èƒ½æµ‹è¯•
    print("-" * 60)
    print()
    print("âš¡ æ€§èƒ½æµ‹è¯•...")
    print()
    
    import time
    
    test_cases = [
        ("ç®€å•é—®é¢˜", "1+1ç­‰äºå‡ ï¼Ÿ"),
        ("ä¸­ç­‰é—®é¢˜", "è¯·åˆ—ä¸¾3ä¸ªæé«˜å·¥ä½œæ•ˆç‡çš„æ–¹æ³•ã€‚"),
    ]
    
    for name, question in test_cases:
        print(f"   æµ‹è¯•: {name}")
        start_time = time.time()
        
        try:
            response = backend.chat(
                messages=[
                    LLMMessage(role="user", content=question)
                ],
                temperature=0.7,
                max_tokens=200
            )
            
            elapsed = time.time() - start_time
            print(f"      è€—æ—¶: {elapsed:.2f}ç§’")
            print(f"      å“åº”é•¿åº¦: {len(response.content)} å­—ç¬¦")
            print()
            
        except Exception as e:
            print(f"      âŒ å¤±è´¥: {e}")
            print()
    
    print("=" * 60)
    print()
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print()
    print("åç«¯é…ç½®æ­£å¸¸ï¼Œå¯ä»¥ä½¿ç”¨ AI åŠŸèƒ½äº†ã€‚")
    print()
    
    return True


if __name__ == "__main__":
    try:
        success = test_backend()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print()
        print("æµ‹è¯•å·²å–æ¶ˆ")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
