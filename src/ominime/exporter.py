"""
Obsidian å¯¼å‡ºæ¨¡å—

å°†æ¯æ—¥åˆ†ææŠ¥å‘Šå¯¼å‡ºä¸º Markdown æ–‡ä»¶ä¿å­˜åˆ° Obsidian
"""

import os
from datetime import date, datetime
from pathlib import Path
from typing import Optional, Dict, List

from .database import get_database
from .analyzer import get_analyzer, DailyReport, ThemeAnalysis
from .config import config
from .llm_backend import get_llm_backend


class ObsidianExporter:
    """
    Obsidian å¯¼å‡ºå™¨
    
    å°†æ¯æ—¥è¾“å…¥è®°å½•å’Œ AI åˆ†æå¯¼å‡ºä¸º Markdown æ–‡ä»¶
    """
    
    def __init__(self, obsidian_path: Optional[str] = None):
        """
        åˆå§‹åŒ–å¯¼å‡ºå™¨
        
        Args:
            obsidian_path: Obsidian vault è·¯å¾„ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–
        """
        self.obsidian_path = Path(
            obsidian_path or 
            os.getenv("OBSIDIAN_PATH") or 
            "/Users/liqiuhua/work/personal/obsidian/personal"
        )
        self.output_dir = self.obsidian_path / "10_Sources" / "OmniMe"
        self.db = get_database()
        self.analyzer = get_analyzer()
    
    def ensure_output_dir(self):
        """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨"""
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def export_daily_report(
        self, 
        target_date: Optional[date] = None,
        include_raw_content: bool = True,
        include_ai_analysis: bool = True
    ) -> Optional[Path]:
        """
        å¯¼å‡ºæ¯æ—¥æŠ¥å‘Šåˆ° Obsidian
        
        Args:
            target_date: ç›®æ ‡æ—¥æœŸï¼Œé»˜è®¤ä»Šå¤©
            include_raw_content: æ˜¯å¦åŒ…å«åŸå§‹è¾“å…¥å†…å®¹
            include_ai_analysis: æ˜¯å¦åŒ…å« AI åˆ†æ
        
        Returns:
            å¯¼å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæ— æ•°æ®åˆ™è¿”å› None
        """
        if target_date is None:
            target_date = date.today()
        
        self.ensure_output_dir()
        
        # è·å–æ•°æ®
        records = self.db.get_records_by_date(target_date)
        if not records:
            return None
        
        # ç”ŸæˆæŠ¥å‘Š
        report = self.analyzer.generate_daily_report(target_date)
        
        # ç”Ÿæˆä¸»é¢˜åˆ†æ
        theme_analysis = None
        if include_ai_analysis and config.ai_enabled:
            theme_analysis = self.analyzer.generate_theme_analysis(target_date)
        
        # æŒ‰åº”ç”¨åˆ†ç»„å†…å®¹
        app_contents = self._group_content_by_app(records)
        
        # ç”Ÿæˆ Markdown å†…å®¹
        markdown = self._generate_markdown(
            target_date=target_date,
            report=report,
            theme_analysis=theme_analysis,
            app_contents=app_contents,
            include_raw_content=include_raw_content,
            include_ai_analysis=include_ai_analysis
        )
        
        # è·å–æ¨¡å‹åç§°
        model_name = self._get_model_name()
        
        # ä¿å­˜æ–‡ä»¶
        weekday_names = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥']
        weekday = weekday_names[target_date.weekday()]
        filename = f"{target_date.strftime('%Y-%m-%d')}-{weekday}-OmniMeæ—¥æŠ¥-{model_name}.md"
        filepath = self.output_dir / filename
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(markdown)
        
        return filepath
    
    def _get_model_name(self) -> str:
        """è·å–å½“å‰ä½¿ç”¨çš„æ¨¡å‹åç§°"""
        try:
            backend = get_llm_backend()
            if backend:
                backend_type = os.getenv("LLM_BACKEND", "openai")
                if backend_type == "ollama":
                    model = os.getenv("OLLAMA_MODEL", "unknown")
                    return model.replace(":", "-")
                elif backend_type == "qwen-local":
                    model = os.getenv("QWEN_MODEL", "qwen-local")
                    return model.split("/")[-1] if "/" in model else model
                elif backend_type == "openai":
                    model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
                    return model
            return "no-ai"
        except Exception:
            return "no-ai"
    
    def _group_content_by_app(self, records) -> Dict[str, Dict]:
        """æŒ‰åº”ç”¨åˆ†ç»„å†…å®¹"""
        app_contents = {}
        
        for record in records:
            app_name = record.display_name or record.app_name
            if app_name not in app_contents:
                app_contents[app_name] = {
                    "total_chars": 0,
                    "sessions": [],
                    "contents": []
                }
            
            app_contents[app_name]["total_chars"] += record.char_count
            if record.content and record.content.strip():
                app_contents[app_name]["contents"].append({
                    "time": record.timestamp.strftime("%H:%M:%S"),
                    "content": record.content.strip()
                })
        
        # æŒ‰å­—ç¬¦æ•°æ’åº
        return dict(sorted(
            app_contents.items(), 
            key=lambda x: x[1]["total_chars"], 
            reverse=True
        ))
    
    def _generate_markdown(
        self,
        target_date: date,
        report: DailyReport,
        theme_analysis: Optional[ThemeAnalysis],
        app_contents: Dict[str, Dict],
        include_raw_content: bool,
        include_ai_analysis: bool
    ) -> str:
        """ç”Ÿæˆ Markdown å†…å®¹"""
        lines = []
        
        weekday_names = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥']
        weekday = weekday_names[target_date.weekday()]
        
        # è·å–æ¨¡å‹åç§°
        model_name = self._get_model_name()
        
        # YAML Front Matter
        lines.append("---")
        lines.append(f"date: {target_date.isoformat()}")
        lines.append(f"weekday: {weekday}")
        lines.append(f"total_chars: {report.total_chars}")
        lines.append(f"total_apps: {report.total_apps}")
        lines.append(f"total_sessions: {report.total_sessions}")
        lines.append(f"ai_model: {model_name}")
        lines.append(f"created: {datetime.now().isoformat()}")
        lines.append("tags:")
        lines.append("  - OmniMe")
        lines.append("  - æ—¥æŠ¥")
        lines.append("  - è¾“å…¥è¿½è¸ª")
        lines.append(f"  - {model_name}")
        lines.append("---")
        lines.append("")
        
        # æ ‡é¢˜
        lines.append(f"# ğŸ“… {target_date.strftime('%Y-%m-%d')} {weekday} è¾“å…¥æ—¥æŠ¥")
        lines.append("")
        
        # æ¦‚è§ˆ
        lines.append("## ğŸ“Š ä»Šæ—¥æ¦‚è§ˆ")
        lines.append("")
        lines.append(f"| æŒ‡æ ‡ | æ•°å€¼ |")
        lines.append(f"|------|------|")
        lines.append(f"| ğŸ“ æ€»å­—ç¬¦æ•° | {report.total_chars:,} |")
        lines.append(f"| ğŸ“± åº”ç”¨æ•°é‡ | {report.total_apps} |")
        lines.append(f"| ğŸ”¢ ä¼šè¯æ•°é‡ | {report.total_sessions} |")
        
        if report.total_time_minutes > 0:
            hours = int(report.total_time_minutes // 60)
            mins = int(report.total_time_minutes % 60)
            time_str = f"{hours}å°æ—¶{mins}åˆ†é’Ÿ" if hours > 0 else f"{mins}åˆ†é’Ÿ"
            lines.append(f"| â±ï¸ æ´»è·ƒæ—¶é—´ | {time_str} |")
        
        lines.append("")
        
        # åº”ç”¨åˆ†å¸ƒ
        if report.app_stats:
            lines.append("## ğŸ“± åº”ç”¨åˆ†å¸ƒ")
            lines.append("")
            lines.append("| åº”ç”¨ | å­—ç¬¦æ•° | å æ¯” |")
            lines.append("|------|--------|------|")
            
            for stat in report.app_stats[:10]:
                percentage = stat.total_chars / report.total_chars * 100 if report.total_chars > 0 else 0
                lines.append(f"| {stat.display_name} | {stat.total_chars:,} | {percentage:.1f}% |")
            
            lines.append("")
        
        # ä¸»çº¿æ´»åŠ¨
        if report.main_activities:
            lines.append("## ğŸ¯ ä¸»çº¿æ´»åŠ¨")
            lines.append("")
            for i, activity in enumerate(report.main_activities, 1):
                lines.append(f"{i}. {activity}")
            lines.append("")
        
        # AI åˆ†æéƒ¨åˆ†
        if include_ai_analysis:
            # åŸºç¡€æ€»ç»“
            if report.summary:
                lines.append("## ğŸ“ æ¯æ—¥æ€»ç»“")
                lines.append("")
                lines.append(report.summary)
                lines.append("")
            
            # ä¸»é¢˜æ·±åº¦åˆ†æ
            if theme_analysis:
                lines.append("## ğŸ¯ ä¸»é¢˜æ·±åº¦åˆ†æ")
                lines.append("")
                
                # ä»Šæ—¥ä¸»é¢˜
                if theme_analysis.themes:
                    lines.append("### ä»Šæ—¥ä¸»é¢˜")
                    lines.append("")
                    for theme in theme_analysis.themes:
                        lines.append(f"- {theme}")
                    lines.append("")
                
                # å·¥ä½œé‡ç‚¹å›é¡¾
                if theme_analysis.work_focus:
                    lines.append("### å·¥ä½œé‡ç‚¹å›é¡¾")
                    lines.append("")
                    lines.append(theme_analysis.work_focus)
                    lines.append("")
                
                # å½“å‰å…³æ³¨
                if theme_analysis.current_interests:
                    lines.append("### å½“å‰å…³æ³¨")
                    lines.append("")
                    for interest in theme_analysis.current_interests:
                        lines.append(f"- {interest}")
                    lines.append("")
                
                # æ´å¯Ÿä¸å¯å‘
                if theme_analysis.insights:
                    lines.append("### ğŸ’¡ æ´å¯Ÿä¸å¯å‘")
                    lines.append("")
                    for insight in theme_analysis.insights:
                        lines.append(f"- âœ¨ {insight}")
                    lines.append("")
                
                # è¯¦ç»†æ€»ç»“
                if theme_analysis.detailed_summary:
                    lines.append("### æ·±åº¦æ€»ç»“")
                    lines.append("")
                    lines.append(theme_analysis.detailed_summary)
                    lines.append("")
            
            # AI å·¥ä½œåˆ†æ
            if report.ai_work_analysis:
                lines.append("## ğŸ¤– AI å·¥ä½œåˆ†æ")
                lines.append("")
                lines.append(report.ai_work_analysis)
                lines.append("")
            
            # å»ºè®®
            if report.suggestions:
                lines.append("## ğŸ’¡ ä¼˜åŒ–å»ºè®®")
                lines.append("")
                for suggestion in report.suggestions:
                    lines.append(f"- {suggestion}")
                lines.append("")
        
        # å·¥ä½œè·¯å¾„åˆ†æ
        if report.work_path:
            lines.append("## ğŸ›¤ï¸ å·¥ä½œè·¯å¾„åˆ†æ")
            lines.append("")
            lines.append(f"- **å·¥ä½œæ¨¡å¼**: {report.work_path.work_pattern}")
            lines.append(f"- **æ•ˆç‡åˆ†æ•°**: {report.work_path.efficiency_score:.1f}/100")
            lines.append(f"- **åº”ç”¨åˆ‡æ¢**: {report.work_path.app_switches} æ¬¡")
            lines.append(f"- **å·¥ä½œç‰‡æ®µ**: {report.work_path.total_segments} ä¸ª")
            lines.append("")
            
            # å³°å€¼æ—¶æ®µ
            if report.work_path.peak_hours:
                lines.append("### â° å³°å€¼æ—¶æ®µ")
                lines.append("")
                for hour, chars in report.work_path.peak_hours[:5]:
                    lines.append(f"- {hour}:00 - {chars:,} å­—ç¬¦")
                lines.append("")
            
            # ä¸“æ³¨æ—¶æ®µ
            if report.work_path.focus_periods:
                lines.append("### ğŸ¯ æ·±åº¦å·¥ä½œæ—¶æ®µ")
                lines.append("")
                for start, end, app in report.work_path.focus_periods[:5]:
                    duration = (end - start).total_seconds() / 60
                    lines.append(f"- {start.strftime('%H:%M')}-{end.strftime('%H:%M')} {app} ({duration:.0f}åˆ†é’Ÿ)")
                lines.append("")
        
        # åŸå§‹è¾“å…¥å†…å®¹
        if include_raw_content and app_contents:
            lines.append("---")
            lines.append("")
            lines.append("## ğŸ“„ åŸå§‹è¾“å…¥å†…å®¹")
            lines.append("")
            lines.append("> [!note] è¯´æ˜")
            lines.append("> ä»¥ä¸‹æ˜¯æŒ‰åº”ç”¨åˆ†ç»„çš„åŸå§‹è¾“å…¥å†…å®¹ï¼Œç”¨äºå›é¡¾å’Œæ£€ç´¢ã€‚")
            lines.append("")
            
            for app_name, data in app_contents.items():
                lines.append(f"### {app_name}")
                lines.append("")
                lines.append(f"*{data['total_chars']:,} å­—ç¬¦*")
                lines.append("")
                
                # åˆå¹¶å†…å®¹
                if data["contents"]:
                    lines.append("```")
                    for item in data["contents"]:
                        content = item["content"]
                        # é™åˆ¶å•æ¡å†…å®¹é•¿åº¦
                        if len(content) > 500:
                            content = content[:500] + "..."
                        lines.append(f"[{item['time']}] {content}")
                    lines.append("```")
                    lines.append("")
        
        # é¡µè„š
        lines.append("---")
        lines.append("")
        lines.append(f"*ç”± OmniMe è‡ªåŠ¨ç”Ÿæˆäº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | AI æ¨¡å‹: {model_name}*")
        
        return "\n".join(lines)


# å…¨å±€å¯¼å‡ºå™¨å®ä¾‹
_exporter_instance: Optional[ObsidianExporter] = None


def get_exporter(obsidian_path: Optional[str] = None) -> ObsidianExporter:
    """è·å–å¯¼å‡ºå™¨å•ä¾‹"""
    global _exporter_instance
    if _exporter_instance is None:
        _exporter_instance = ObsidianExporter(obsidian_path)
    return _exporter_instance


def export_daily_to_obsidian(
    target_date: Optional[date] = None,
    include_raw_content: bool = True,
    include_ai_analysis: bool = True,
    obsidian_path: Optional[str] = None
) -> Optional[Path]:
    """
    ä¾¿æ·å‡½æ•°ï¼šå¯¼å‡ºæ¯æ—¥æŠ¥å‘Šåˆ° Obsidian
    
    Args:
        target_date: ç›®æ ‡æ—¥æœŸï¼Œé»˜è®¤ä»Šå¤©
        include_raw_content: æ˜¯å¦åŒ…å«åŸå§‹è¾“å…¥å†…å®¹
        include_ai_analysis: æ˜¯å¦åŒ…å« AI åˆ†æ
        obsidian_path: Obsidian vault è·¯å¾„
    
    Returns:
        å¯¼å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæ— æ•°æ®åˆ™è¿”å› None
    """
    exporter = ObsidianExporter(obsidian_path) if obsidian_path else get_exporter()
    return exporter.export_daily_report(
        target_date=target_date,
        include_raw_content=include_raw_content,
        include_ai_analysis=include_ai_analysis
    )
